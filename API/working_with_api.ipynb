{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f5ce7c-ce23-4bb6-b822-1e6f9ffea67e",
   "metadata": {},
   "source": [
    "## Working with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330646d0-13a1-43ff-8c38-60647191b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77062a95-05ec-4d14-a4c1-a715d89cbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c46bbe-18e2-4eba-b47d-46d35e7bde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=dashscope_api_key, base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\")\n",
    "QWQ_MODEL = \"qwq-plus\"\n",
    "QWEN_MODEL = \"qwen-plus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24312596-e5cf-434c-873b-13d5fdcf879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic dreams,  \n",
      "AI woven in ethical threads,  \n",
      "future whispers.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": \"Write a haiku about Anthropic\"}\n",
    "    ],\n",
    "    max_tokens= 1000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1b6714-61bd-4641-868c-3e2ee5087c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-69474b61-fee6-9a4a-b42b-15c7c740b6c9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Anthropic dreams,  \\nAI woven in ethical threads,  \\nfuture whispers.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1744440900, model='qwen-plus', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=15, total_tokens=30, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdfdfe-c089-46d2-be13-749c1a074067",
   "metadata": {},
   "source": [
    "## The Mesaages Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a7685a8-0d2f-4784-a2a4-5902395b6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages= [\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Only speak to me in Chinese\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"ä½ å¥½ï¼\"},\n",
    "        {\"role\": \"user\", \"content\": \"How are you?\"}\n",
    "    ],\n",
    "    max_tokens = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ccdf98-d951-423e-a8b9-133bd4c96b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢å…³å¿ƒï¼ä½ å‘¢ï¼Ÿ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8220a-7b8c-4e52-91fe-df04506c60d0",
   "metadata": {},
   "source": [
    "### Simple Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8815483b-3c87-4a90-9a6e-238d61adc239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Chatbot (type 'quit' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  Hello! How can I assist you today? ğŸ˜Š\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  å¯ä»¥ä»‹ç»ä¸€äº›å…³äºopen ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸€äº›å…³äº **OpenAI** çš„åŸºæœ¬ä¿¡æ¯å’ŒèƒŒæ™¯ä»‹ç»ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### ä»€ä¹ˆæ˜¯ OpenAIï¼Ÿ\n",
      "OpenAI æ˜¯ä¸€å®¶é¢†å…ˆçš„äººå·¥æ™ºèƒ½ç ”ç©¶å®éªŒå®¤ï¼Œæˆç«‹äº **2015å¹´**ï¼Œæ€»éƒ¨ä½äºç¾å›½åŠ åˆ©ç¦å°¼äºšå·æ—§é‡‘å±±ã€‚å®ƒç”±ä¸€ç¾¤æŠ€æœ¯ä¸“å®¶ã€ä¼ä¸šå®¶å’ŒæŠ•èµ„è€…å…±åŒåˆ›ç«‹ï¼ŒåŒ…æ‹¬ **åŸƒéš†Â·é©¬æ–¯å…‹ï¼ˆElon Muskï¼‰**ã€**å±±å§†Â·é˜¿å°”ç‰¹æ›¼ï¼ˆSam Altmanï¼‰** å’Œ **æ ¼é›·æ ¼Â·å¸ƒç½—å…‹æ›¼ï¼ˆGreg Brockmanï¼‰** ç­‰ã€‚\n",
      "\n",
      "OpenAI çš„ç›®æ ‡æ˜¯ç¡®ä¿äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å®‰å…¨å‘å±•ï¼Œå¹¶ä»¥è´Ÿè´£ä»»çš„æ–¹å¼æ¨åŠ¨ AI æŠ€æœ¯çš„è¿›æ­¥ã€‚å®ƒçš„ä½¿å‘½æ˜¯åˆ›é€ ä¸€ç§é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰ï¼Œè¿™ç§äººå·¥æ™ºèƒ½èƒ½å¤Ÿåƒäººç±»ä¸€æ ·æ€è€ƒå’Œå­¦ä¹ ï¼ŒåŒæ—¶ç¡®ä¿å…¶å¯¹ç¤¾ä¼šçš„ç§¯æå½±å“ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI çš„ä¸»è¦äº§å“å’ŒæŠ€æœ¯\n",
      "OpenAI å¼€å‘äº†è®¸å¤šçŸ¥åçš„äººå·¥æ™ºèƒ½æ¨¡å‹å’ŒæŠ€æœ¯ï¼Œä»¥ä¸‹æ˜¯å…¶ä¸­ä¸€äº›é‡è¦çš„é¡¹ç›®ï¼š\n",
      "\n",
      "1. **GPT ç³»åˆ—ï¼ˆGenerative Pre-trained Transformerï¼‰**\n",
      "   - GPT æ˜¯ OpenAI æœ€è‘—åçš„è¯­è¨€æ¨¡å‹ç³»åˆ—ã€‚\n",
      "   - ç›®å‰å·²ç»å‘å¸ƒäº†å¤šä¸ªç‰ˆæœ¬ï¼šGPT-1ã€GPT-2ã€GPT-3 å’Œæœ€æ–°çš„ GPT-4ã€‚\n",
      "   - è¿™äº›æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„æ–‡æœ¬ï¼Œå¦‚æ–‡ç« ã€è¯—æ­Œã€ä»£ç ç­‰ï¼Œè¿˜å¯ä»¥å›ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ç­‰ã€‚\n",
      "\n",
      "2. **ChatGPT**\n",
      "   - åŸºäº GPT ç³»åˆ—å¼€å‘çš„å¯¹è¯å¼ AI æ¨¡å‹ã€‚\n",
      "   - å®ƒèƒ½å¤Ÿä¸ç”¨æˆ·è¿›è¡Œè‡ªç„¶æµç•…çš„å¯¹è¯ï¼Œå¸®åŠ©è§£å†³å„ç§é—®é¢˜ã€‚\n",
      "   - ChatGPT å·²ç»æˆä¸ºå…¨çƒèŒƒå›´å†…æœ€å—æ¬¢è¿çš„ AI èŠå¤©æœºå™¨äººä¹‹ä¸€ã€‚\n",
      "\n",
      "3. **DALLÂ·E**\n",
      "   - DALLÂ·E æ˜¯ OpenAI å¼€å‘çš„ä¸€ç§å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚\n",
      "   - ç”¨æˆ·å¯ä»¥é€šè¿‡è¾“å…¥æ–‡å­—æè¿°æ¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚\n",
      "   - å®ƒç»“åˆäº†æ–‡æœ¬ç†è§£å’Œå›¾åƒç”Ÿæˆçš„èƒ½åŠ›ã€‚\n",
      "\n",
      "4. **Codex**\n",
      "   - Codex æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºç¼–ç¨‹çš„ AI æ¨¡å‹ã€‚\n",
      "   - å®ƒèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”Ÿæˆä»£ç ï¼Œæˆ–è€…å¸®åŠ©å¼€å‘è€…è°ƒè¯•å’Œä¼˜åŒ–ä»£ç ã€‚\n",
      "   - GitHub Copilot å°±æ˜¯åŸºäº Codex æŠ€æœ¯å¼€å‘çš„å·¥å…·ã€‚\n",
      "\n",
      "5. **Whisper**\n",
      "   - Whisper æ˜¯ä¸€ç§è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œèƒ½å¤Ÿå°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬ã€‚\n",
      "   - å®ƒæ”¯æŒå¤šç§è¯­è¨€ï¼Œå…·æœ‰å¾ˆé«˜çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI çš„æ ¸å¿ƒç†å¿µ\n",
      "OpenAI çš„æˆç«‹åˆè¡·æ˜¯ä¸ºäº†ç ”ç©¶å’Œå¼€å‘å®‰å…¨çš„é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼ŒOpenAI éµå¾ªä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒåŸåˆ™ï¼š\n",
      "1. **å®‰å…¨æ€§**ï¼šç¡®ä¿ AI æŠ€æœ¯ä¸ä¼šå¯¹äººç±»ç¤¾ä¼šé€ æˆå¨èƒã€‚\n",
      "2. **å¼€æ”¾æ€§**ï¼šè™½ç„¶ OpenAI çš„éƒ¨åˆ†æŠ€æœ¯æ˜¯å•†ä¸šåŒ–çš„ï¼Œä½†å®ƒä¹Ÿè‡´åŠ›äºå‘å…¬ä¼—åˆ†äº«ç ”ç©¶æˆæœã€‚\n",
      "3. **è´£ä»»æ€§**ï¼šå¼ºè°ƒ AI æŠ€æœ¯çš„ç¤¾ä¼šå½±å“ï¼ŒåŠªåŠ›é¿å…æ»¥ç”¨æˆ–è¯¯ç”¨ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI çš„å•†ä¸šæ¨¡å¼\n",
      "OpenAI æœ€åˆæ˜¯ä¸€ä¸ªéè¥åˆ©ç»„ç»‡ï¼Œä½†åœ¨ 2019 å¹´æˆç«‹äº†è¥åˆ©æ€§å­å…¬å¸ **OpenAI LP**ï¼Œä»¥ä¾¿æ›´å¥½åœ°å¸å¼•æŠ•èµ„å’Œæ”¯æŒæŠ€æœ¯ç ”å‘ã€‚ç›®å‰ï¼ŒOpenAI æä¾›ä»¥ä¸‹å‡ ç§å•†ä¸šæ¨¡å¼ï¼š\n",
      "1. **API æœåŠ¡**ï¼šä¼ä¸šå¯ä»¥é€šè¿‡ OpenAI çš„ API ä½¿ç”¨å…¶æ¨¡å‹ï¼ˆå¦‚ GPTã€DALLÂ·E ç­‰ï¼‰ã€‚\n",
      "2. **æˆæƒåˆä½œ**ï¼šä¸å…¶ä»–å…¬å¸åˆä½œï¼Œå°† AI æŠ€æœ¯é›†æˆåˆ°ä»–ä»¬çš„äº§å“ä¸­ã€‚\n",
      "3. **è®¢é˜…æœåŠ¡**ï¼šæä¾›ä»˜è´¹è®¢é˜…è®¡åˆ’ï¼Œè®©ç”¨æˆ·è®¿é—®æ›´é«˜çº§çš„åŠŸèƒ½ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI çš„ç«äº‰å¯¹æ‰‹\n",
      "åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸï¼ŒOpenAI çš„ä¸»è¦ç«äº‰å¯¹æ‰‹åŒ…æ‹¬ï¼š\n",
      "1. **Google DeepMind**ï¼šè°·æ­Œæ——ä¸‹çš„ AI å®éªŒå®¤ï¼Œä¸“æ³¨äºæ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚\n",
      "2. **Anthropic**ï¼šå¼€å‘äº† Claude ç³»åˆ— AI æ¨¡å‹ï¼Œæ³¨é‡å¯¹è¯å®‰å…¨æ€§å’Œå¯æ§æ€§ã€‚\n",
      "3. **é˜¿é‡Œå·´å·´é€šä¹‰å®éªŒå®¤**ï¼šå¼€å‘äº†é€šä¹‰åƒé—®ï¼ˆQwenï¼‰ç­‰å¤§æ¨¡å‹ã€‚\n",
      "4. **Metaï¼ˆFacebookï¼‰**ï¼šå¼€å‘äº† Llama ç³»åˆ—å¼€æºæ¨¡å‹ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœä½ å¯¹ OpenAI æˆ–å…¶æŠ€æœ¯æœ‰ä»»ä½•å…·ä½“é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶æé—®ï¼ ğŸ˜Š\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  è¿˜æœ‰å…¶ä»–ä¿¡æ¯ä¹ˆï¼Ÿå…³äºAPI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  å½“ç„¶å¯ä»¥ï¼å…³äº OpenAI çš„ **API**ï¼Œè¿™é‡Œæœ‰ä¸€äº›æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œå¸®åŠ©ä½ æ›´å¥½åœ°äº†è§£å®ƒçš„åŠŸèƒ½ã€ä½¿ç”¨æ–¹æ³•ä»¥åŠé€‚ç”¨åœºæ™¯ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ä»€ä¹ˆæ˜¯ OpenAI APIï¼Ÿ\n",
      "OpenAI API æ˜¯ä¸€ä¸ªåŸºäºäº‘çš„æœåŠ¡æ¥å£ï¼Œå…è®¸å¼€å‘è€…å’Œä¼ä¸šé€šè¿‡ç®€å•çš„ HTTP è¯·æ±‚è®¿é—® OpenAI çš„å¼ºå¤§ AI æ¨¡å‹ï¼ˆå¦‚ GPT ç³»åˆ—ã€DALLÂ·Eã€Whisper ç­‰ï¼‰ã€‚å®ƒæä¾›äº†ä¸€ç§ç®€å•çš„æ–¹å¼æ¥å°† AI æŠ€æœ¯é›†æˆåˆ°å„ç§åº”ç”¨ç¨‹åºä¸­ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI API çš„ä¸»è¦åŠŸèƒ½\n",
      "ä»¥ä¸‹æ˜¯ OpenAI API æä¾›çš„ä¸€äº›æ ¸å¿ƒåŠŸèƒ½ï¼š\n",
      "\n",
      "1. **æ–‡æœ¬ç”Ÿæˆ**\n",
      "   - ä½¿ç”¨ GPT ç³»åˆ—æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„æ–‡æœ¬ã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šæ–‡ç« æ’°å†™ã€åˆ›æ„å†™ä½œã€è‡ªåŠ¨å›å¤ç­‰ã€‚\n",
      "\n",
      "2. **å¯¹è¯ç³»ç»Ÿ**\n",
      "   - æ„å»ºæ™ºèƒ½èŠå¤©æœºå™¨äººã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šå®¢æœç³»ç»Ÿã€è™šæ‹ŸåŠ©æ‰‹ç­‰ã€‚\n",
      "\n",
      "3. **ä»£ç ç”Ÿæˆ**\n",
      "   - ä½¿ç”¨ Codex æ¨¡å‹ç”Ÿæˆæˆ–è¡¥å…¨ä»£ç ã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šå¼€å‘è¾…åŠ©å·¥å…·ã€ä»£ç æ¨èç³»ç»Ÿã€‚\n",
      "\n",
      "4. **å›¾åƒç”Ÿæˆ**\n",
      "   - ä½¿ç”¨ DALLÂ·E æ¨¡å‹æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾åƒã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šè®¾è®¡ã€è‰ºæœ¯åˆ›ä½œã€å¹¿å‘Šç´ æç”Ÿæˆã€‚\n",
      "\n",
      "5. **è¯­éŸ³è¯†åˆ«**\n",
      "   - ä½¿ç”¨ Whisper æ¨¡å‹å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬ã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šå®æ—¶å­—å¹•ã€è¯­éŸ³ç¬”è®°ç­‰ã€‚\n",
      "\n",
      "6. **æƒ…æ„Ÿåˆ†æ**\n",
      "   - åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢ã€è´Ÿé¢æˆ–ä¸­æ€§ï¼‰ã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šèˆ†æƒ…ç›‘æ§ã€ç”¨æˆ·åé¦ˆåˆ†æã€‚\n",
      "\n",
      "7. **ç¿»è¯‘**\n",
      "   - å°†æ–‡æœ¬ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šå¤šè¯­è¨€æ”¯æŒã€å›½é™…åŒ–åº”ç”¨ã€‚\n",
      "\n",
      "8. **åˆ†ç±»ä¸æ‘˜è¦**\n",
      "   - å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»æˆ–ç”Ÿæˆæ‘˜è¦ã€‚\n",
      "   - åº”ç”¨åœºæ™¯ï¼šæ–°é—»æ‘˜è¦ã€é‚®ä»¶åˆ†ç±»ç­‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### å¦‚ä½•ä½¿ç”¨ OpenAI APIï¼Ÿ\n",
      "ä»¥ä¸‹æ˜¯ä½¿ç”¨ OpenAI API çš„åŸºæœ¬æ­¥éª¤ï¼š\n",
      "\n",
      "1. **æ³¨å†Œè´¦æˆ·**\n",
      "   - è®¿é—® [OpenAI å®˜ç½‘](https://openai.com/) å¹¶æ³¨å†Œä¸€ä¸ªå¼€å‘è€…è´¦æˆ·ã€‚\n",
      "   - æ³¨å†Œåï¼Œä½ ä¼šè·å¾—ä¸€ä¸ª API å¯†é’¥ï¼ˆAPI Keyï¼‰ï¼Œè¿™æ˜¯è°ƒç”¨ API æ‰€éœ€çš„å‡­æ®ã€‚\n",
      "\n",
      "2. **é€‰æ‹©æ¨¡å‹**\n",
      "   - æ ¹æ®ä½ çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚ä¾‹å¦‚ï¼š\n",
      "     - æ–‡æœ¬ç”Ÿæˆï¼š`text-davinci-003` æˆ– `gpt-3.5-turbo`\n",
      "     - å›¾åƒç”Ÿæˆï¼š`DALLÂ·E`\n",
      "     - è¯­éŸ³è¯†åˆ«ï¼š`Whisper`\n",
      "\n",
      "3. **å‘é€è¯·æ±‚**\n",
      "   - ä½¿ç”¨ HTTP è¯·æ±‚ï¼ˆé€šå¸¸é€šè¿‡ `curl` æˆ–ç¼–ç¨‹è¯­è¨€åº“ï¼‰å‘ API å‘é€æ•°æ®ã€‚\n",
      "   - ç¤ºä¾‹è¯·æ±‚æ ¼å¼ï¼ˆPython ä»£ç ï¼‰ï¼š\n",
      "     ```python\n",
      "     import openai\n",
      "\n",
      "     # è®¾ç½® API å¯†é’¥\n",
      "     openai.api_key = \"ä½ çš„_API_Key\"\n",
      "\n",
      "     # è°ƒç”¨ GPT æ¨¡å‹ç”Ÿæˆæ–‡æœ¬\n",
      "     response = openai.Completion.create(\n",
      "         engine=\"text-davinci-003\",\n",
      "         prompt=\"å†™ä¸€é¦–å…³äºç§‹å¤©çš„è¯—ã€‚\",\n",
      "         max_tokens=100\n",
      "     )\n",
      "\n",
      "     print(response.choices[0].text)\n",
      "     ```\n",
      "\n",
      "4. **å¤„ç†å“åº”**\n",
      "   - API ä¼šè¿”å› JSON æ ¼å¼çš„å“åº”æ•°æ®ï¼Œä½ å¯ä»¥ä»ä¸­æå–æ‰€éœ€çš„ç»“æœã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI API çš„å®šä»·æ¨¡å¼\n",
      "OpenAI API çš„ä½¿ç”¨æ˜¯æŒ‰éœ€è®¡è´¹çš„ï¼Œå…·ä½“è´¹ç”¨å–å†³äºä»¥ä¸‹å‡ ä¸ªå› ç´ ï¼š\n",
      "1. **ä½¿ç”¨çš„æ¨¡å‹**ï¼šä¸åŒæ¨¡å‹çš„è´¹ç”¨ä¸åŒã€‚ä¾‹å¦‚ï¼ŒGPT-3 çš„ä»·æ ¼ä½äº GPT-4ã€‚\n",
      "2. **è¾“å…¥/è¾“å‡ºçš„ token æ•°é‡**ï¼šæ¯æ¬¡è¯·æ±‚çš„æ–‡æœ¬é•¿åº¦ä¼šå½±å“è´¹ç”¨ã€‚\n",
      "3. **è¯·æ±‚é¢‘ç‡**ï¼šé«˜é¢‘è¯·æ±‚å¯èƒ½ä¼šå¯¼è‡´æ›´é«˜çš„æˆæœ¬ã€‚\n",
      "\n",
      "#### ç¤ºä¾‹å®šä»·ï¼ˆæˆªè‡³ 2023 å¹´ï¼Œå…·ä½“ä»·æ ¼å¯èƒ½æœ‰æ‰€å˜åŒ–ï¼‰ï¼š\n",
      "- **GPT-3 (text-davinci-003)**ï¼šæ¯ 1,000 tokens çº¦ $0.02ã€‚\n",
      "- **GPT-4**ï¼šæ¯ 1,000 tokens çº¦ $0.03 è‡³ $0.12ï¼ˆè§†ç‰ˆæœ¬è€Œå®šï¼‰ã€‚\n",
      "- **DALLÂ·E**ï¼šæ¯å¼ å›¾ç‰‡çº¦ $0.02ã€‚\n",
      "- **Whisper**ï¼šæ¯åˆ†é’ŸéŸ³é¢‘çº¦ $0.006ã€‚\n",
      "\n",
      "OpenAI è¿˜æä¾›å…è´¹è¯•ç”¨é¢åº¦ï¼Œå¸®åŠ©å¼€å‘è€…ç†Ÿæ‚‰å…¶æœåŠ¡ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI API çš„ä¼˜åŠ¿\n",
      "1. **æ˜“ç”¨æ€§**ï¼šAPI æ¥å£ç®€å•æ˜“ç”¨ï¼Œé€‚åˆå„ç§æŠ€æœ¯æ°´å¹³çš„å¼€å‘è€…ã€‚\n",
      "2. **çµæ´»æ€§**ï¼šæ”¯æŒå¤šç§æ¨¡å‹å’ŒåŠŸèƒ½ï¼Œæ»¡è¶³ä¸åŒåº”ç”¨åœºæ™¯çš„éœ€æ±‚ã€‚\n",
      "3. **å¼ºå¤§çš„æ€§èƒ½**ï¼šåŸºäº OpenAI æœ€å…ˆè¿›çš„ AI æ¨¡å‹ï¼Œç”Ÿæˆç»“æœè´¨é‡é«˜ã€‚\n",
      "4. **\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple Chatbot (type 'quit' to exit)\")\n",
    "\n",
    "# Store conversation history\n",
    "messages = []\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You: \")\n",
    "    # Check for quit command\n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Add user message to history \n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    try:\n",
    "        # Get response from LLM\n",
    "        response = client.chat.completions.create(\n",
    "            model = QWEN_MODEL,\n",
    "            max_tokens = 1000,\n",
    "            messages = messages\n",
    "        )\n",
    "        # Extract and print LLM response\n",
    "        asst_message = response.choices[0].message.content\n",
    "        print(\"Assistant: \", asst_message)\n",
    "\n",
    "        # Add assistant response to history\n",
    "        messages.append({\"role\": \"assistant\", \"content\": asst_message})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfffce9-8320-44e0-b716-c42f2e54816f",
   "metadata": {},
   "source": [
    "### Prefilling the Assistant Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "780be2a5-c5b5-48b7-9943-487341327c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oink, oink go the pigs in the pen,  \n",
      "Rolling in mud where their joys begin.  \n",
      "With curly tails and snouts so keen,  \n",
      "They sniff and dig through the earth's soft sheen.  \n",
      "\n",
      "In pastures green or barnyard gray,  \n",
      "Pigs find their peace come night or day.  \n",
      "Contented grunts as sunsets glow,  \n",
      "A piggy paradiseâ€”we ought to know!  \n",
      "\n",
      "So here's to the pigs, both big and small,  \n",
      "Who teach us joy can be found in all.  \n",
      "For even a hog has a story to tell,  \n",
      "Oink, oinkâ€”it's the truth we hold well.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Write a short poem about pigs\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Oink\"}\n",
    "    ],\n",
    "    max_tokens = 1000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecba022-e139-4926-b426-8b7a456b9e2a",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc8968-6711-4f47-a048-5e657e81eadd",
   "metadata": {},
   "source": [
    "### Max Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c464e3-5dc0-4eda-b024-e7f34ffb2821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Rise of Large Language Models (LLMs): Transforming Communication and Computation**\n",
      "\n",
      "In recent years, artificial intelligence (AI) has made remarkable strides, with one of its most transformative developments being the advent of large language models (LLMs). These sophisticated AI systems have revolutionized how we interact with machines, process information, and even create content. LLMs are powerful tools capable of generating coherent text, answering complex questions, translating languages, writing code, and more. This essay explores what\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages= [\n",
    "        {\"role\": \"user\", \"content\": \"Write me an essay on LLMs\"}\n",
    "    ],\n",
    "    max_tokens= 100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec9929bd-6c1c-4828-9c6c-b1b7f4f6b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-bd0599a3-3043-96c7-95d9-b0a495a3813a', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='**The Rise of Large Language Models (LLMs): Transforming Communication and Computation**\\n\\nIn recent years, artificial intelligence (AI) has made remarkable strides, with one of its most transformative developments being the advent of large language models (LLMs). These sophisticated AI systems have revolutionized how we interact with machines, process information, and even create content. LLMs are powerful tools capable of generating coherent text, answering complex questions, translating languages, writing code, and more. This essay explores what', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1744442620, model='qwen-plus', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=16, total_tokens=116, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603c767-6f81-4a01-9649-e10499d98a9d",
   "metadata": {},
   "source": [
    "### Stop Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac66238c-0749-44ba-8f9b-ce585ba092a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a numbered, ordered list of technical topics you should consider learning if you want to work with Large Language Models (LLMs):\n",
      "\n",
      "1. **Natural Language Processing (NLP)**\n",
      "   - Basics of NLP\n",
      "   - Text preprocessing techniques\n",
      "   - Tokenization, stemming, and lemmatization\n",
      "\n",
      "2. **Machine Learning Fundamentals**\n",
      "   - Supervised vs unsupervised learning\n",
      "   - Regression and classification algorithms\n",
      "   - Evaluation metrics (accuracy, precision, recall, F1-score)\n",
      "\n",
      "3. **Deep Learning**\n",
      "   - Neural networks architecture\n",
      "   - Backpropagation and gradient descent\n",
      "   - Convolutional Neural Networks (CNNs)\n",
      "   - Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRUs)\n",
      "\n",
      "4. **Transformers**\n",
      "   - Attention mechanism\n",
      "   - Self-attention and multi-head attention\n",
      "   - Encoder-decoder architecture\n",
      "   - Positional encoding\n",
      "\n",
      "5. **Pretrained Language Models**\n",
      "   - BERT, GPT, T5, RoBERTa\n",
      "   - Fine-tuning pretrained models for specific tasks\n",
      "   - Transfer learning in NLP\n",
      "\n",
      "6. **Data Handling and Management**\n",
      "   - Working with large datasets\n",
      "   - Data augmentation techniques for text data\n",
      "   - Data cleaning and preprocessing pipelines\n",
      "\n",
      "7. **Evaluation Metrics for LLMs**\n",
      "   - Perplexity\n",
      "   - BLEU, ROUGE, METEOR scores\n",
      "   - Human evaluation methods\n",
      "\n",
      "8. **Prompt Engineering**\n",
      "   - Designing effective prompts for different use cases\n",
      "   - Chain-of-thought prompting\n",
      "   - Few-shot vs zero-shot prompting\n",
      "\n",
      "9. **Ethics and Bias in LLMs**\n",
      "   - Identifying and mitigating biases\n",
      "   - Fairness and accountability in AI systems\n",
      "   - Privacy concerns and data protection\n",
      "\n",
      "10. **Scalability and Optimization**\n",
      "    - Model compression techniques (quantization, pruning)\n",
      "    - Efficient inference strategies\n",
      "    - Distributed training and parallel computing\n",
      "\n",
      "11. **Programming Skills**\n",
      "    - Python (essential for most ML/DL libraries)\n",
      "    - Familiarity with libraries like TensorFlow, PyTorch, Hugging Face Transformers\n",
      "    - Version control using Git\n",
      "\n",
      "12. **Cloud Computing and Infrastructure**\n",
      "    - AWS, Google Cloud, or Azure services for deploying models\n",
      "    - Containerization with Docker\n",
      "    - Kubernetes for orchestration\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a numbered, ordered list of technical topics\n",
    "I should learn if I want to work to LLMs\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens = 500\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "623864a5-37f4-4bea-82b5-b60e49ee747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a numbered, ordered list of technical topics you should learn if you want to work with Large Language Models (LLMs):\n",
      "\n",
      "1. **Natural Language Processing (NLP) Fundamentals**\n",
      "   - Tokenization\n",
      "   - Part-of-speech tagging\n",
      "   - Named Entity Recognition (NER)\n",
      "   - Sentiment Analysis\n",
      "\n",
      "2. **Machine Learning Basics**\n",
      "   - Supervised vs. Unsupervised Learning\n",
      "   - Regression and Classification\n",
      "   - Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)\n",
      "\n",
      "3. **Deep Learning**\n",
      "   - Neural Networks\n",
      "   - Backpropagation\n",
      "   - Activation Functions (ReLU, Sigmoid, Tanh)\n",
      "   - Loss Functions (Cross-Entropy, Mean Squared Error)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a numbered, ordered list of technical topics\n",
    "I should learn if I want to work to LLMs\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens = 500,\n",
    "    stop = [\"4.\"]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b668faa8-0525-49c3-a8e5-8b758d891087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-5c9ffaa5-bb34-96e8-8a51-da8a3e880d33', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is a numbered, ordered list of technical topics you should learn if you want to work with Large Language Models (LLMs):\\n\\n1. **Natural Language Processing (NLP) Fundamentals**\\n   - Tokenization\\n   - Part-of-speech tagging\\n   - Named Entity Recognition (NER)\\n   - Sentiment Analysis\\n\\n2. **Machine Learning Basics**\\n   - Supervised vs. Unsupervised Learning\\n   - Regression and Classification\\n   - Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)\\n\\n3. **Deep Learning**\\n   - Neural Networks\\n   - Backpropagation\\n   - Activation Functions (ReLU, Sigmoid, Tanh)\\n   - Loss Functions (Cross-Entropy, Mean Squared Error)\\n\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1744443035, model='qwen-plus', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=150, prompt_tokens=31, total_tokens=181, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a395776-e9d9-4a5f-8e77-7f4c5f222643",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02f19d52-083d-459a-92b4-edbb6897ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_temperature():\n",
    "    temperatures = [0, 1]\n",
    "\n",
    "    for temperature in temperatures:\n",
    "        print(f\"Prompting LLM three times with temperature of {temperature}\")\n",
    "        print(\"=============\")\n",
    "\n",
    "        for i in range(3):\n",
    "            response = client.chat.completions.create(\n",
    "                model = QWEN_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"Prompt {i+1}: Come up with a name for an alien planet. Respond with a single word\"}],\n",
    "                max_tokens = 100,\n",
    "                temperature = temperature\n",
    "            )\n",
    "            print(f\"Response {i+1}: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eee0a1c-64d7-43b4-a634-dc00d4b57b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompting LLM three times with temperature of 0\n",
      "=============\n",
      "Response 1: Zogarath\n",
      "Response 2: Zorathion\n",
      "Response 3: Xenora\n",
      "Prompting LLM three times with temperature of 1\n",
      "=============\n",
      "Response 1: Xylopp\n",
      "Response 2: Xenthara\n",
      "Response 3: Xenora\n"
     ]
    }
   ],
   "source": [
    "demonstrate_temperature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb55139-fd82-4373-a091-50580fcc158d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
