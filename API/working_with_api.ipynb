{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f5ce7c-ce23-4bb6-b822-1e6f9ffea67e",
   "metadata": {},
   "source": [
    "## Working with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330646d0-13a1-43ff-8c38-60647191b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77062a95-05ec-4d14-a4c1-a715d89cbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c46bbe-18e2-4eba-b47d-46d35e7bde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=dashscope_api_key, base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\")\n",
    "QWQ_MODEL = \"qwq-plus\"\n",
    "QWEN_MODEL = \"qwen-plus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24312596-e5cf-434c-873b-13d5fdcf879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic dreams,  \n",
      "AI woven in ethical threads,  \n",
      "future whispers.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": \"Write a haiku about Anthropic\"}\n",
    "    ],\n",
    "    max_tokens= 1000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1b6714-61bd-4641-868c-3e2ee5087c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-69474b61-fee6-9a4a-b42b-15c7c740b6c9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Anthropic dreams,  \\nAI woven in ethical threads,  \\nfuture whispers.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1744440900, model='qwen-plus', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=15, total_tokens=30, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdfdfe-c089-46d2-be13-749c1a074067",
   "metadata": {},
   "source": [
    "## The Mesaages Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a7685a8-0d2f-4784-a2a4-5902395b6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages= [\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Only speak to me in Chinese\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"你好！\"},\n",
    "        {\"role\": \"user\", \"content\": \"How are you?\"}\n",
    "    ],\n",
    "    max_tokens = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ccdf98-d951-423e-a8b9-133bd4c96b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我很好，谢谢关心！你呢？'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8220a-7b8c-4e52-91fe-df04506c60d0",
   "metadata": {},
   "source": [
    "### Simple Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8815483b-3c87-4a90-9a6e-238d61adc239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Chatbot (type 'quit' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  Hello! How can I assist you today? 😊\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  可以介绍一些关于open ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  当然可以！以下是一些关于 **OpenAI** 的基本信息和背景介绍：\n",
      "\n",
      "---\n",
      "\n",
      "### 什么是 OpenAI？\n",
      "OpenAI 是一家领先的人工智能研究实验室，成立于 **2015年**，总部位于美国加利福尼亚州旧金山。它由一群技术专家、企业家和投资者共同创立，包括 **埃隆·马斯克（Elon Musk）**、**山姆·阿尔特曼（Sam Altman）** 和 **格雷格·布罗克曼（Greg Brockman）** 等。\n",
      "\n",
      "OpenAI 的目标是确保人工智能技术的安全发展，并以负责任的方式推动 AI 技术的进步。它的使命是创造一种通用人工智能（AGI），这种人工智能能够像人类一样思考和学习，同时确保其对社会的积极影响。\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI 的主要产品和技术\n",
      "OpenAI 开发了许多知名的人工智能模型和技术，以下是其中一些重要的项目：\n",
      "\n",
      "1. **GPT 系列（Generative Pre-trained Transformer）**\n",
      "   - GPT 是 OpenAI 最著名的语言模型系列。\n",
      "   - 目前已经发布了多个版本：GPT-1、GPT-2、GPT-3 和最新的 GPT-4。\n",
      "   - 这些模型能够生成高质量的文本，如文章、诗歌、代码等，还可以回答问题、进行对话等。\n",
      "\n",
      "2. **ChatGPT**\n",
      "   - 基于 GPT 系列开发的对话式 AI 模型。\n",
      "   - 它能够与用户进行自然流畅的对话，帮助解决各种问题。\n",
      "   - ChatGPT 已经成为全球范围内最受欢迎的 AI 聊天机器人之一。\n",
      "\n",
      "3. **DALL·E**\n",
      "   - DALL·E 是 OpenAI 开发的一种图像生成模型。\n",
      "   - 用户可以通过输入文字描述来生成高质量的图像。\n",
      "   - 它结合了文本理解和图像生成的能力。\n",
      "\n",
      "4. **Codex**\n",
      "   - Codex 是一种专门用于编程的 AI 模型。\n",
      "   - 它能够根据自然语言指令生成代码，或者帮助开发者调试和优化代码。\n",
      "   - GitHub Copilot 就是基于 Codex 技术开发的工具。\n",
      "\n",
      "5. **Whisper**\n",
      "   - Whisper 是一种语音识别模型，能够将语音转换为文本。\n",
      "   - 它支持多种语言，具有很高的准确性和效率。\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI 的核心理念\n",
      "OpenAI 的成立初衷是为了研究和开发安全的通用人工智能（AGI）。为了实现这一目标，OpenAI 遵循以下几个核心原则：\n",
      "1. **安全性**：确保 AI 技术不会对人类社会造成威胁。\n",
      "2. **开放性**：虽然 OpenAI 的部分技术是商业化的，但它也致力于向公众分享研究成果。\n",
      "3. **责任性**：强调 AI 技术的社会影响，努力避免滥用或误用。\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI 的商业模式\n",
      "OpenAI 最初是一个非营利组织，但在 2019 年成立了营利性子公司 **OpenAI LP**，以便更好地吸引投资和支持技术研发。目前，OpenAI 提供以下几种商业模式：\n",
      "1. **API 服务**：企业可以通过 OpenAI 的 API 使用其模型（如 GPT、DALL·E 等）。\n",
      "2. **授权合作**：与其他公司合作，将 AI 技术集成到他们的产品中。\n",
      "3. **订阅服务**：提供付费订阅计划，让用户访问更高级的功能。\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI 的竞争对手\n",
      "在人工智能领域，OpenAI 的主要竞争对手包括：\n",
      "1. **Google DeepMind**：谷歌旗下的 AI 实验室，专注于深度学习和强化学习。\n",
      "2. **Anthropic**：开发了 Claude 系列 AI 模型，注重对话安全性和可控性。\n",
      "3. **阿里巴巴通义实验室**：开发了通义千问（Qwen）等大模型。\n",
      "4. **Meta（Facebook）**：开发了 Llama 系列开源模型。\n",
      "\n",
      "---\n",
      "\n",
      "如果你对 OpenAI 或其技术有任何具体问题，欢迎随时提问！ 😊\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  还有其他信息么？关于API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  当然可以！关于 OpenAI 的 **API**，这里有一些更详细的信息，帮助你更好地了解它的功能、使用方法以及适用场景。\n",
      "\n",
      "---\n",
      "\n",
      "### 什么是 OpenAI API？\n",
      "OpenAI API 是一个基于云的服务接口，允许开发者和企业通过简单的 HTTP 请求访问 OpenAI 的强大 AI 模型（如 GPT 系列、DALL·E、Whisper 等）。它提供了一种简单的方式来将 AI 技术集成到各种应用程序中。\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI API 的主要功能\n",
      "以下是 OpenAI API 提供的一些核心功能：\n",
      "\n",
      "1. **文本生成**\n",
      "   - 使用 GPT 系列模型生成高质量的文本。\n",
      "   - 应用场景：文章撰写、创意写作、自动回复等。\n",
      "\n",
      "2. **对话系统**\n",
      "   - 构建智能聊天机器人。\n",
      "   - 应用场景：客服系统、虚拟助手等。\n",
      "\n",
      "3. **代码生成**\n",
      "   - 使用 Codex 模型生成或补全代码。\n",
      "   - 应用场景：开发辅助工具、代码推荐系统。\n",
      "\n",
      "4. **图像生成**\n",
      "   - 使用 DALL·E 模型根据文本描述生成图像。\n",
      "   - 应用场景：设计、艺术创作、广告素材生成。\n",
      "\n",
      "5. **语音识别**\n",
      "   - 使用 Whisper 模型将语音转换为文本。\n",
      "   - 应用场景：实时字幕、语音笔记等。\n",
      "\n",
      "6. **情感分析**\n",
      "   - 分析文本的情感倾向（正面、负面或中性）。\n",
      "   - 应用场景：舆情监控、用户反馈分析。\n",
      "\n",
      "7. **翻译**\n",
      "   - 将文本从一种语言翻译成另一种语言。\n",
      "   - 应用场景：多语言支持、国际化应用。\n",
      "\n",
      "8. **分类与摘要**\n",
      "   - 对文本进行分类或生成摘要。\n",
      "   - 应用场景：新闻摘要、邮件分类等。\n",
      "\n",
      "---\n",
      "\n",
      "### 如何使用 OpenAI API？\n",
      "以下是使用 OpenAI API 的基本步骤：\n",
      "\n",
      "1. **注册账户**\n",
      "   - 访问 [OpenAI 官网](https://openai.com/) 并注册一个开发者账户。\n",
      "   - 注册后，你会获得一个 API 密钥（API Key），这是调用 API 所需的凭据。\n",
      "\n",
      "2. **选择模型**\n",
      "   - 根据你的需求选择合适的模型。例如：\n",
      "     - 文本生成：`text-davinci-003` 或 `gpt-3.5-turbo`\n",
      "     - 图像生成：`DALL·E`\n",
      "     - 语音识别：`Whisper`\n",
      "\n",
      "3. **发送请求**\n",
      "   - 使用 HTTP 请求（通常通过 `curl` 或编程语言库）向 API 发送数据。\n",
      "   - 示例请求格式（Python 代码）：\n",
      "     ```python\n",
      "     import openai\n",
      "\n",
      "     # 设置 API 密钥\n",
      "     openai.api_key = \"你的_API_Key\"\n",
      "\n",
      "     # 调用 GPT 模型生成文本\n",
      "     response = openai.Completion.create(\n",
      "         engine=\"text-davinci-003\",\n",
      "         prompt=\"写一首关于秋天的诗。\",\n",
      "         max_tokens=100\n",
      "     )\n",
      "\n",
      "     print(response.choices[0].text)\n",
      "     ```\n",
      "\n",
      "4. **处理响应**\n",
      "   - API 会返回 JSON 格式的响应数据，你可以从中提取所需的结果。\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI API 的定价模式\n",
      "OpenAI API 的使用是按需计费的，具体费用取决于以下几个因素：\n",
      "1. **使用的模型**：不同模型的费用不同。例如，GPT-3 的价格低于 GPT-4。\n",
      "2. **输入/输出的 token 数量**：每次请求的文本长度会影响费用。\n",
      "3. **请求频率**：高频请求可能会导致更高的成本。\n",
      "\n",
      "#### 示例定价（截至 2023 年，具体价格可能有所变化）：\n",
      "- **GPT-3 (text-davinci-003)**：每 1,000 tokens 约 $0.02。\n",
      "- **GPT-4**：每 1,000 tokens 约 $0.03 至 $0.12（视版本而定）。\n",
      "- **DALL·E**：每张图片约 $0.02。\n",
      "- **Whisper**：每分钟音频约 $0.006。\n",
      "\n",
      "OpenAI 还提供免费试用额度，帮助开发者熟悉其服务。\n",
      "\n",
      "---\n",
      "\n",
      "### OpenAI API 的优势\n",
      "1. **易用性**：API 接口简单易用，适合各种技术水平的开发者。\n",
      "2. **灵活性**：支持多种模型和功能，满足不同应用场景的需求。\n",
      "3. **强大的性能**：基于 OpenAI 最先进的 AI 模型，生成结果质量高。\n",
      "4. **\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple Chatbot (type 'quit' to exit)\")\n",
    "\n",
    "# Store conversation history\n",
    "messages = []\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You: \")\n",
    "    # Check for quit command\n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Add user message to history \n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    try:\n",
    "        # Get response from LLM\n",
    "        response = client.chat.completions.create(\n",
    "            model = QWEN_MODEL,\n",
    "            max_tokens = 1000,\n",
    "            messages = messages\n",
    "        )\n",
    "        # Extract and print LLM response\n",
    "        asst_message = response.choices[0].message.content\n",
    "        print(\"Assistant: \", asst_message)\n",
    "\n",
    "        # Add assistant response to history\n",
    "        messages.append({\"role\": \"assistant\", \"content\": asst_message})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfffce9-8320-44e0-b716-c42f2e54816f",
   "metadata": {},
   "source": [
    "### Prefilling the Assistant Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "780be2a5-c5b5-48b7-9943-487341327c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oink, oink go the pigs in the pen,  \n",
      "Rolling in mud where their joys begin.  \n",
      "With curly tails and snouts so keen,  \n",
      "They sniff and dig through the earth's soft sheen.  \n",
      "\n",
      "In pastures green or barnyard gray,  \n",
      "Pigs find their peace come night or day.  \n",
      "Contented grunts as sunsets glow,  \n",
      "A piggy paradise—we ought to know!  \n",
      "\n",
      "So here's to the pigs, both big and small,  \n",
      "Who teach us joy can be found in all.  \n",
      "For even a hog has a story to tell,  \n",
      "Oink, oink—it's the truth we hold well.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Write a short poem about pigs\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Oink\"}\n",
    "    ],\n",
    "    max_tokens = 1000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecba022-e139-4926-b426-8b7a456b9e2a",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc8968-6711-4f47-a048-5e657e81eadd",
   "metadata": {},
   "source": [
    "### Max Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c464e3-5dc0-4eda-b024-e7f34ffb2821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Rise of Large Language Models (LLMs): Transforming Communication and Computation**\n",
      "\n",
      "In recent years, artificial intelligence (AI) has made remarkable strides, with one of its most transformative developments being the advent of large language models (LLMs). These sophisticated AI systems have revolutionized how we interact with machines, process information, and even create content. LLMs are powerful tools capable of generating coherent text, answering complex questions, translating languages, writing code, and more. This essay explores what\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages= [\n",
    "        {\"role\": \"user\", \"content\": \"Write me an essay on LLMs\"}\n",
    "    ],\n",
    "    max_tokens= 100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec9929bd-6c1c-4828-9c6c-b1b7f4f6b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-bd0599a3-3043-96c7-95d9-b0a495a3813a', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='**The Rise of Large Language Models (LLMs): Transforming Communication and Computation**\\n\\nIn recent years, artificial intelligence (AI) has made remarkable strides, with one of its most transformative developments being the advent of large language models (LLMs). These sophisticated AI systems have revolutionized how we interact with machines, process information, and even create content. LLMs are powerful tools capable of generating coherent text, answering complex questions, translating languages, writing code, and more. This essay explores what', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1744442620, model='qwen-plus', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=16, total_tokens=116, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603c767-6f81-4a01-9649-e10499d98a9d",
   "metadata": {},
   "source": [
    "### Stop Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac66238c-0749-44ba-8f9b-ce585ba092a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a numbered, ordered list of technical topics you should consider learning if you want to work with Large Language Models (LLMs):\n",
      "\n",
      "1. **Natural Language Processing (NLP)**\n",
      "   - Basics of NLP\n",
      "   - Text preprocessing techniques\n",
      "   - Tokenization, stemming, and lemmatization\n",
      "\n",
      "2. **Machine Learning Fundamentals**\n",
      "   - Supervised vs unsupervised learning\n",
      "   - Regression and classification algorithms\n",
      "   - Evaluation metrics (accuracy, precision, recall, F1-score)\n",
      "\n",
      "3. **Deep Learning**\n",
      "   - Neural networks architecture\n",
      "   - Backpropagation and gradient descent\n",
      "   - Convolutional Neural Networks (CNNs)\n",
      "   - Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRUs)\n",
      "\n",
      "4. **Transformers**\n",
      "   - Attention mechanism\n",
      "   - Self-attention and multi-head attention\n",
      "   - Encoder-decoder architecture\n",
      "   - Positional encoding\n",
      "\n",
      "5. **Pretrained Language Models**\n",
      "   - BERT, GPT, T5, RoBERTa\n",
      "   - Fine-tuning pretrained models for specific tasks\n",
      "   - Transfer learning in NLP\n",
      "\n",
      "6. **Data Handling and Management**\n",
      "   - Working with large datasets\n",
      "   - Data augmentation techniques for text data\n",
      "   - Data cleaning and preprocessing pipelines\n",
      "\n",
      "7. **Evaluation Metrics for LLMs**\n",
      "   - Perplexity\n",
      "   - BLEU, ROUGE, METEOR scores\n",
      "   - Human evaluation methods\n",
      "\n",
      "8. **Prompt Engineering**\n",
      "   - Designing effective prompts for different use cases\n",
      "   - Chain-of-thought prompting\n",
      "   - Few-shot vs zero-shot prompting\n",
      "\n",
      "9. **Ethics and Bias in LLMs**\n",
      "   - Identifying and mitigating biases\n",
      "   - Fairness and accountability in AI systems\n",
      "   - Privacy concerns and data protection\n",
      "\n",
      "10. **Scalability and Optimization**\n",
      "    - Model compression techniques (quantization, pruning)\n",
      "    - Efficient inference strategies\n",
      "    - Distributed training and parallel computing\n",
      "\n",
      "11. **Programming Skills**\n",
      "    - Python (essential for most ML/DL libraries)\n",
      "    - Familiarity with libraries like TensorFlow, PyTorch, Hugging Face Transformers\n",
      "    - Version control using Git\n",
      "\n",
      "12. **Cloud Computing and Infrastructure**\n",
      "    - AWS, Google Cloud, or Azure services for deploying models\n",
      "    - Containerization with Docker\n",
      "    - Kubernetes for orchestration\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a numbered, ordered list of technical topics\n",
    "I should learn if I want to work to LLMs\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens = 500\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "623864a5-37f4-4bea-82b5-b60e49ee747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a numbered, ordered list of technical topics you should learn if you want to work with Large Language Models (LLMs):\n",
      "\n",
      "1. **Natural Language Processing (NLP) Fundamentals**\n",
      "   - Tokenization\n",
      "   - Part-of-speech tagging\n",
      "   - Named Entity Recognition (NER)\n",
      "   - Sentiment Analysis\n",
      "\n",
      "2. **Machine Learning Basics**\n",
      "   - Supervised vs. Unsupervised Learning\n",
      "   - Regression and Classification\n",
      "   - Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)\n",
      "\n",
      "3. **Deep Learning**\n",
      "   - Neural Networks\n",
      "   - Backpropagation\n",
      "   - Activation Functions (ReLU, Sigmoid, Tanh)\n",
      "   - Loss Functions (Cross-Entropy, Mean Squared Error)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a numbered, ordered list of technical topics\n",
    "I should learn if I want to work to LLMs\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = QWEN_MODEL,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens = 500,\n",
    "    stop = [\"4.\"]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b668faa8-0525-49c3-a8e5-8b758d891087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-5c9ffaa5-bb34-96e8-8a51-da8a3e880d33', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is a numbered, ordered list of technical topics you should learn if you want to work with Large Language Models (LLMs):\\n\\n1. **Natural Language Processing (NLP) Fundamentals**\\n   - Tokenization\\n   - Part-of-speech tagging\\n   - Named Entity Recognition (NER)\\n   - Sentiment Analysis\\n\\n2. **Machine Learning Basics**\\n   - Supervised vs. Unsupervised Learning\\n   - Regression and Classification\\n   - Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)\\n\\n3. **Deep Learning**\\n   - Neural Networks\\n   - Backpropagation\\n   - Activation Functions (ReLU, Sigmoid, Tanh)\\n   - Loss Functions (Cross-Entropy, Mean Squared Error)\\n\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1744443035, model='qwen-plus', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=150, prompt_tokens=31, total_tokens=181, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a395776-e9d9-4a5f-8e77-7f4c5f222643",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02f19d52-083d-459a-92b4-edbb6897ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_temperature():\n",
    "    temperatures = [0, 1]\n",
    "\n",
    "    for temperature in temperatures:\n",
    "        print(f\"Prompting LLM three times with temperature of {temperature}\")\n",
    "        print(\"=============\")\n",
    "\n",
    "        for i in range(3):\n",
    "            response = client.chat.completions.create(\n",
    "                model = QWEN_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"Prompt {i+1}: Come up with a name for an alien planet. Respond with a single word\"}],\n",
    "                max_tokens = 100,\n",
    "                temperature = temperature\n",
    "            )\n",
    "            print(f\"Response {i+1}: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eee0a1c-64d7-43b4-a634-dc00d4b57b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompting LLM three times with temperature of 0\n",
      "=============\n",
      "Response 1: Zogarath\n",
      "Response 2: Zorathion\n",
      "Response 3: Xenora\n",
      "Prompting LLM three times with temperature of 1\n",
      "=============\n",
      "Response 1: Xylopp\n",
      "Response 2: Xenthara\n",
      "Response 3: Xenora\n"
     ]
    }
   ],
   "source": [
    "demonstrate_temperature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb55139-fd82-4373-a091-50580fcc158d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
